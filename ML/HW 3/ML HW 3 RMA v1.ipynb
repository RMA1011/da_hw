{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# ДЗ ML3:\n",
    "# 1. Датасет titanic, разделить на train/test в пропорции 0.7/0.3\n",
    "# 2. Предсказать возраст Age на основании других параметров (отберите сами какие)\n",
    "# 3. Подобрать оптимальные гиперпараметры модели с помощью GridSearch, в идеале получить лучшее качество на test\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Резюме\n",
    "\n",
    "# Результат линейной регрессии на тесте после оптимизации (MSE):  -175.53050966534144\n",
    "# Лучшие параметры регрессии: {'fit_intercept': True, 'positive': False}\n",
    "\n",
    "# Лучший показатель DecisionTreeRegressor на тесте при оптимизации (MSE):  -205.57545932291464\n",
    "# Лучшие параметры дерева: {'max_depth': 2, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
    "\n",
    "# Лучший показатель XGBRegressor на тесте при оптимизации (MSE):  -204.26866346743162\n",
    "# Лушчие параметры XGB: {'colsample_bytree': 0.3, 'gamma': 0.0, 'max_depth': 5, 'min_child_weight': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('https://raw.githubusercontent.com/RMA1011/da_hw/main/ML/HW%203/titanic.csv')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Обработка данных\n",
    "raw_data.dropna(inplace = True)\n",
    "features = raw_data[['Survived','Pclass','Sex','SibSp','Fare']]\n",
    "features['Sex'].replace({'male':0,'female':1}, inplace = True)\n",
    "target = raw_data['Age']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат линейной регрессии на тесте до оптимизации (MSE):  175.53050966534144\n",
      "Результат линейной регрессии на обучении после оптимизации (MSE):  239.40141875015624\n",
      "Результат линейной регрессии на тесте после оптимизации (MSE):  175.53050966534144\n",
      "Лучшие параметры:  {'fit_intercept': True, 'positive': False}\n"
     ]
    }
   ],
   "source": [
    "#### Пробуем линейную регрессию\n",
    "lin_mod = LinearRegression()\n",
    "fit_mod = LinearRegression().fit(X = X_train,y = y_train)\n",
    "pred_lin = fit_mod.predict(X_test)\n",
    "print('Результат линейной регрессии на тесте до оптимизации (MSE): ', MSE(y_test, pred_lin))\n",
    "parameters = {'fit_intercept': [True,False],\n",
    "'positive':[True, False]}\n",
    "lin_grid = GridSearchCV(estimator = lin_mod, scoring = 'neg_mean_squared_error',param_grid = parameters, cv = 5, n_jobs =-1, refit = True)\n",
    "lin_grid = lin_grid.fit(X_train, y_train)\n",
    "best_lin_model = lin_grid.best_estimator_\n",
    "lin_pred = best_lin_model.predict(X_test)\n",
    "\n",
    "print('Результат линейной регрессии на обучении после оптимизации (MSE): ', -1*lin_grid.best_score_)\n",
    "print('Результат линейной регрессии на тесте после оптимизации (MSE): ', MSE(y_test, lin_pred))\n",
    "print('Лучшие параметры: ', lin_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший показатель на обучении до оптимизации (MSE):  342.5092072727272\n",
      "Лучшие параметры:  {'max_depth': 2, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
      "Лучший показатель на обучении при оптимизации (MSE):  227.80952042290446\n",
      "Лучший показатель на тесте при оптимизации (MSE):  205.57545932291464\n"
     ]
    }
   ],
   "source": [
    "#### Пробуем дерево\n",
    "decis_tree = DecisionTreeRegressor(random_state=42)\n",
    "parameters_tree = {\n",
    "    'max_depth':  [1,2,3,4,5,6,7,8,9,10],\n",
    "    'min_samples_split': [2,3,4,5,6,7,8,9,10],\n",
    "    'min_samples_leaf': [2,3,4,5,6,7,8,9,10]\n",
    "}\n",
    "\n",
    "fit_tree = decis_tree.fit(X_train, y_train)\n",
    "fit_tree_pred = fit_tree.predict(X_test)\n",
    "print('Лучший показатель на обучении до оптимизации (MSE): ', MSE(y_test, fit_tree_pred))\n",
    "\n",
    "decis_grid = GridSearchCV(\n",
    "    estimator = decis_tree, \n",
    "    param_grid = parameters_tree,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = 5,\n",
    "    refit = True     \n",
    ")\n",
    "\n",
    "decis_grid = decis_grid.fit(X_train, y_train)\n",
    "print('Лучшие параметры: ',decis_grid.best_params_)\n",
    "print('Лучший показатель на обучении при оптимизации (MSE): ', -1*decis_grid.best_score_)\n",
    "best_decis_model = decis_grid.best_estimator_\n",
    "best_decis_model = best_decis_model.fit(X_train,y_train)\n",
    "best_predicted = best_decis_model.predict(X_test)\n",
    "print('Лучший показатель на тесте при оптимизации (MSE): ', MSE(y_test, best_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат на тесте до оптимизации (MSE) :  208.103283\n",
      "Лучшие параметры:  {'colsample_bytree': 0.3, 'gamma': 0.0, 'max_depth': 5, 'min_child_weight': 7}\n",
      "Лучший показатель на обучении при оптимизации (MSE):  228.82802988909128\n",
      "Лучший показатель на тесте при оптимизации (MSE):  204.26866346743162\n"
     ]
    }
   ],
   "source": [
    "### Пробуем xgboost!\n",
    "\n",
    "xgb_r = xgb.XGBRegressor(objective ='reg:squarederror',\n",
    "                  n_estimators = 10, seed = RANDOM_STATE)\n",
    "\n",
    "xgb_r.fit(X_train, y_train)\n",
    "xgb_pred = xgb_r.predict(X_test)\n",
    "print(\"Результат на тесте до оптимизации (MSE) : % f\" %(MSE(y_test, xgb_pred)))\n",
    "\n",
    "parameters_xgb = [\n",
    "    {\n",
    "    #'learning rate': (0.05,0.10,0.15),\n",
    "    'max_depth': [3,4,5,6,8],\n",
    "    'min_child_weight': [1,3,5,7],\n",
    "    'gamma': [0.0,0.1,0.2],\n",
    "    'colsample_bytree': [0.3, 0.4]\n",
    "    }\n",
    "]\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator = xgb_r, \n",
    "    param_grid = parameters_xgb,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = 5,\n",
    "    refit = True)\n",
    "\n",
    "xgb_grid = xgb_grid.fit(X_train, y_train)\n",
    "print('Лучшие параметры: ',xgb_grid.best_params_)\n",
    "print('Лучший показатель на обучении при оптимизации (MSE): ', -1*xgb_grid.best_score_)\n",
    "best_xgb_model = xgb_grid.best_estimator_\n",
    "best_xgb_model = best_xgb_model.fit(X_train,y_train)\n",
    "xgb_opt_pred = best_xgb_model.predict(X_test)\n",
    "print('Лучший показатель на тесте при оптимизации (MSE): ', MSE(y_test, xgb_opt_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1835615888dd5962b87b68afec97ab70ea34dcf06a519d9b229643f1246f266c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
